<!doctype html>
<html>
<head>  
    <title>Nesrine Malik's Article</title>                
</head>

<body> 
    <h1>Response to Article</h1>   

    <p> Nesrine Malik’s article is something i have been thinking of: nowadays the internet feels “unreal”, we can’t really tell what’s actually happening and there are  endless sludge of AI-generated junks out there. She is mainly touching two channels paralelly - one of them is real “genuine” photos,videos from trusted resources,news,wars etc. ; on the other hand she mentions “cartoonish” fantasies, “giant cat balls”, unrealistic AI generated pictures that involves famous (or political )figures using for propaganda. The scary part is making everything blend until you question “what am i seeing?” 

      How Malik highlights this political weaponization is faboulous.  For instance, Right-wing fantasy videos on YouTube, White House's own X, Studio Ghibli trend to post an AI-rendered image of a sobbing Dominican woman being arrested by ICE. On the other side, Chinese AI videos after tariff hikes - overwheighting American workers in sweatshops, prompting as “the potential of the American worker.” While all these happening, these cheap propagandas spread through trusted family chats on WhatsApp where no one checks if it is true or not as long as it directed to you from your trustworthy family members.
      
      I see this daily in New York. My feed mixes footage of ICE raids in Queens, campus protests getting broken up, and Gaza horrors with absurd AI "trad wife" images of smiling, submissive homemakers in spotless kitchens, or blond nuclear families as the "desirable future.” As Malik states Prof. Roland Meyer, generative AI is structurally conservative—trained on biased data that favors white, traditional, heteronormative norms. It  manufactures  nostalgia, packaging white supremacy. Meanwhile, big companies reward the chaos because they all care about is less labor or human labor needed.
      
      The desensitization is real and serious. Real terrible events, like violence or suffering, appear right next to silly AI memes—like JD Vance shown as a giant baby—or peaceful pictures of cozy cabins with snow. This makes big problems feel like normal things you just scroll past quickly.
      
      In a big city like New York, people see deportations happening close by and hear talks about how tariffs hurt local jobs. But seeing too many shocking images online makes us less motivated to do something about it. We understand the world has serious problems, but online everything mixes together—the real and the fake—so it all feels both too real and not real at the same time.
      
      Nesrine Malik is spot on in asserting that this phenomenon is far from accidental. Major technology platforms deliberately prioritize such content because it generates powerful engagement—those addictive dopamine surges from likes, shares, and reactions translate directly into revenue. The consequence is a vicious cycle: even as it leaves users feeling paralyzed and overwhelmed, the system floods feeds with more of the same.
      
      We do not have too little information; we have too much in a broken system that makes serious things seem small and unimportant. The solution begins when we stop joining in. For example, we can be careful with messages from family on WhatsApp, ask for better rules on platforms, or stop and check if something is true before we share it.
      
      As Malik states, “I refuse to engage with these intrusive new AI features under any circumstances—over my dead body”. Unless social media companies shift their priorities from profit-driven slop to safeguarding factual reality, society risks gradually drifting toward far greater calamities, unaware and unmoved. 
      </p>   
      <a href="https://github.com/mrrufat/medpl150/blob/main/index.html">
        Click to go back to main html page
      </a> 
</body>
</html>